## ipvs. Если при запросе на VIP сделать подряд несколько запросов (например, for i in {1..50}; do curl -I -s 172.28.128.200>/dev/null; done ), ответы будут получены почти мгновенно. Тем не менее, в выводе ipvsadm -Ln еще некоторое время будут висеть активные InActConn. Почему так происходит?

Согласно документации LVS (пункт 4.11), это нормальное поведение для HTTP, значения в колонке InActConn будут продолжать "висеть" до time out соединения. Значение timeout может достигать 60 и более секунд.

---

## На лекции мы познакомились отдельно с ipvs и отдельно с keepalived. Воспользовавшись этими знаниями, совместите технологии вместе (VIP должен подниматься демоном keepalived). Приложите конфигурационные файлы, которые у вас получились, и продемонстрируйте работу получившейся конструкции. Используйте для директора отдельный хост, не совмещая его с риалом! Подобная схема возможна, но выходит за рамки рассмотренного на лекции.

По образу того Vagrantfile, которым поделились в slack, составил такой:
```
# -*- mode: ruby -*-
# vi: set ft=ruby :

boxes = {
  'client' => '11',
  'lb1' => '101',
  'lb2' => '102',
  'web1' => '201',
  'web2' => '202',
}

Vagrant.configure("2") do |config|
  config.vm.network "private_network", virtualbox__intnet: true, auto_config: false
  config.vm.box = "bento/ubuntu-20.04"

  boxes.each do |k, v|
    config.vm.define k do |node|
      node.vm.provision "shell" do |s|
        s.inline = "hostname $1;"\
          "ip addr add $2 dev eth1;"\
          "ip link set dev eth1 up;"\
          "apt -y install nginx;"
        s.args = [k, "192.168.1.#{v}/24"]
      end
    end
  end
end
```

В иотге получил 5 виртуальных машин: клиент (11), балансировщики (101 и 102), реальные сервера (201 и 202)

На обоих балансировщиках установил keepalived и добавил следующие кофиги:

lb1:
```
vrrp_instance ip1 {
  state MASTER
  interface eth1
  virtual_router_id 1
  priority 100
  virtual_ipaddress {
    192.168.1.10/24 dev eth1 label eth1:10
  }
}

virtual_server 192.168.1.10 80 {
  lvs_sched rr
  lvs_method DR
  protocol TCP
  delay_loop 5
  real_server 192.168.1.201 80 {
    weight 1
    TCP_CHECK {
      connect_timeout 2
    }
  }
  real_server 192.168.1.202 80 {
    weight 1
    TCP_CHECK {
      connect_timeout 2
    }
  }
}
```

lb2:
```
vrrp_instance ip1 {
  state BACKUP
  interface eth1
  virtual_router_id 1
  priority 50
  virtual_ipaddress {
    192.168.1.10/24 dev eth1 label eth1:10
  }
}

virtual_server 192.168.1.10 80 {
  lvs_sched rr
  lvs_method DR
  protocol TCP
  delay_loop 5
  real_server 192.168.1.201 80 {
    weight 1
    TCP_CHECK {
      connect_timeout 2
    }
  }
  real_server 192.168.1.202 80 {
    weight 1
    TCP_CHECK {
      connect_timeout 2
    }
  }
}
```

На реальных серверах выполнил инструкции со слайдов ipvsadm DR демо, часть 3. И заменил вывод дефолтной index.html страницы на `RealServer 1` и `RealServer 2` соответсвенно

В результате при запуске curl на клиенте получаю
```
$ for i in {1..10}; do curl 192.168.1.10; done

RealServer 2
RealServer 1
RealServer 2
RealServer 1
RealServer 2
RealServer 1
RealServer 2
RealServer 1
RealServer 2
RealServer 1
```

В то же время, выполняю на мастер ноде балансировщика:
```
$ ipvsadm -Lnc
IPVS connection entries
pro expire state       source             virtual            destination
TCP 00:09  FIN_WAIT    192.168.1.11:57804 192.168.1.10:80    192.168.1.202:80
TCP 00:09  FIN_WAIT    192.168.1.11:57802 192.168.1.10:80    192.168.1.201:80
TCP 00:09  FIN_WAIT    192.168.1.11:57798 192.168.1.10:80    192.168.1.201:80
TCP 00:09  FIN_WAIT    192.168.1.11:57810 192.168.1.10:80    192.168.1.201:80
TCP 00:04  FIN_WAIT    192.168.1.11:57778 192.168.1.10:80    192.168.1.201:80
TCP 00:04  FIN_WAIT    192.168.1.11:57792 192.168.1.10:80    192.168.1.202:80
TCP 00:04  FIN_WAIT    192.168.1.11:57784 192.168.1.10:80    192.168.1.202:80
TCP 00:09  FIN_WAIT    192.168.1.11:57800 192.168.1.10:80    192.168.1.202:80
TCP 00:09  FIN_WAIT    192.168.1.11:57814 192.168.1.10:80    192.168.1.201:80
TCP 00:09  FIN_WAIT    192.168.1.11:57808 192.168.1.10:80    192.168.1.202:80
...
```

В то время как аналогичный вывод на BACKUP балансировщике пуст

После этого выключаю MASTER

`curl` отработал точно так же, вывод `ipvsadm -Lnc` на втором балансировщике показывает аналогичный результат тому что был получен ранее на первом, что говорит о том, что запасной балансировщик теперь отвечает за траффик

---

## В лекции мы использовали только 1 VIP адрес для балансировки. У такого подхода несколько отрицательных моментов, один из которых – невозможность активного использования нескольких хостов (1 адрес может только переехать с master на standby). Подумайте, сколько адресов оптимально использовать, если мы хотим без какой-либо деградации выдерживать потерю 1 из 3 хостов при входящем трафике 1.5 Гбит/с и физических линках хостов в 1 Гбит/с? Предполагается, что мы хотим задействовать 3 балансировщика в активном режиме (то есть не 2 адреса на 3 хоста, один из которых в обычное время простаивает).

Возможно, я неправильно понял вопрос или мне просто не хватило знаний/смекалки, но ответ как-то напрашивается сам собой:

Нужно иметь 2 VIP на 3 активных хоста. Допустим, адреса 10 и 20, тогда, допустим, 2 из трех хостов могут обслуживать адрес 10, один будет обслуживать адрес 20. Если отвалится один из хостов, обслуживающих адрес 10, то ничего не произойдет, 2 оставшихся продолжат работу. При проблемах на хосте с адресом 20, один из первых двух может забрать его траффик. Даже если трафие в 1,5 Гбит/с делить на 2 хоста с гигабитным подключением, этого должно хватить. 

Либо я совсем все не так понял.
